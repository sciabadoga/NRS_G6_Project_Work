{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n",
    "\n",
    "![KNN](pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Satisfaction Analysis\n",
    "\n",
    "A survey in order to evaluate 20 different healthcare structures. 2000 customers have evaluated, with a 1-10 scale, each of six features of the service:\n",
    "\n",
    "1. Courtesy\n",
    "2. Clarity\n",
    "3. Competence\n",
    "4. Condition (of the structure)\n",
    "5. Promptness (of the service)\n",
    "6. Opening times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Poverty_Code  CRM_Segment Company_Type  Direction_Meeting  \\\n",
      "0   LISTED-2            0          6.0       LISTED                  1   \n",
      "1   LISTED-9            0         11.0       LISTED                  0   \n",
      "2  LISTED-14            0          6.0       LISTED                  1   \n",
      "3  LISTED-30            0          6.0       LISTED                  1   \n",
      "4  LISTED-38            0         11.0       LISTED                  0   \n",
      "\n",
      "   Low_Seniority  High_Seniority  Employees Income_Level New_Client  \\\n",
      "0              1             8.0        420            I        NEW   \n",
      "1              2             8.0        180            F        NEW   \n",
      "2              2             8.0        310            P   EXISTING   \n",
      "3              2             8.0        320            Q   EXISTING   \n",
      "4              4             8.0        300            Q   EXISTING   \n",
      "\n",
      "   Number_Meetings First_Meeting Last_Meeting  Travel_First_Meeting  \\\n",
      "0                1      09/07/10     09/07/10                 247.0   \n",
      "1                0           NaN          NaN                   NaN   \n",
      "2                1      09/09/10     09/09/10                 242.0   \n",
      "3                1      09/16/10     09/16/10                 252.0   \n",
      "4                0           NaN          NaN                   NaN   \n",
      "\n",
      "   Travel_Last_Meeting Size_Indicator  \n",
      "0                247.0            S-M  \n",
      "1                  NaN              S  \n",
      "2                242.0              S  \n",
      "3                252.0              S  \n",
      "4                  NaN              S  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRM_Segment</th>\n",
       "      <th>Direction_Meeting</th>\n",
       "      <th>Low_Seniority</th>\n",
       "      <th>High_Seniority</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Number_Meetings</th>\n",
       "      <th>Travel_First_Meeting</th>\n",
       "      <th>Travel_Last_Meeting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4192.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4076.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>3609.000000</td>\n",
       "      <td>3609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.913884</td>\n",
       "      <td>0.859286</td>\n",
       "      <td>4.450952</td>\n",
       "      <td>8.392051</td>\n",
       "      <td>621.455952</td>\n",
       "      <td>1.098810</td>\n",
       "      <td>261.880576</td>\n",
       "      <td>229.280410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.752059</td>\n",
       "      <td>0.347768</td>\n",
       "      <td>2.580262</td>\n",
       "      <td>1.737038</td>\n",
       "      <td>419.525088</td>\n",
       "      <td>0.608739</td>\n",
       "      <td>79.061852</td>\n",
       "      <td>53.353651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-204.000000</td>\n",
       "      <td>-204.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>234.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>261.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3990.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>749.000000</td>\n",
       "      <td>749.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRM_Segment  Direction_Meeting  Low_Seniority  High_Seniority  \\\n",
       "count  4192.000000        4200.000000    4200.000000     4076.000000   \n",
       "mean      7.913884           0.859286       4.450952        8.392051   \n",
       "std       2.752059           0.347768       2.580262        1.737038   \n",
       "min       2.000000           0.000000       0.000000        1.000000   \n",
       "25%       6.000000           1.000000       2.000000        8.000000   \n",
       "50%       7.000000           1.000000       6.000000        8.000000   \n",
       "75%      11.000000           1.000000       6.000000        8.000000   \n",
       "max      12.000000           1.000000      10.000000       12.000000   \n",
       "\n",
       "         Employees  Number_Meetings  Travel_First_Meeting  Travel_Last_Meeting  \n",
       "count  4200.000000      4200.000000           3609.000000          3609.000000  \n",
       "mean    621.455952         1.098810            261.880576           229.280410  \n",
       "std     419.525088         0.608739             79.061852            53.353651  \n",
       "min       0.000000         0.000000           -204.000000          -204.000000  \n",
       "25%     340.000000         1.000000            209.000000           198.000000  \n",
       "50%     574.000000         1.000000            250.000000           234.000000  \n",
       "75%     810.000000         1.000000            286.000000           261.000000  \n",
       "max    3990.000000         2.000000            749.000000           749.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"C:\\\\Users\\\\datel080\\\\Downloads\\\\Project_Work\\\\crm_model.csv\")\n",
    "#import pandas as pd\n",
    "#data_df = pd.read_csv(\"C:\\Users\\datel080\\Downloads\\Project_Work\\finance_model.csv\",index_col=0)\n",
    "#data_dfcrm_model\n",
    "\n",
    "df2.head()\n",
    "\n",
    "print(df2.head())\n",
    "\n",
    "df2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID Deposit_Date Special_Pay  Price  Refund_Option  \\\n",
      "0  3124-40201     01/23/10          SA    366              0   \n",
      "1  4124-40201     01/23/10          SA    385              0   \n",
      "2   877-40289     04/21/10          SA   1704              0   \n",
      "3  2638-40289     04/21/10          SA   1789              0   \n",
      "4   326-40330     06/01/10          SA    655              0   \n",
      "\n",
      "   Refund_Option_Cancelled  Refund_Percentage  Automatic_Pay_Rate  Revenue  \n",
      "0                        0                0.0                 0.0      385  \n",
      "1                        0                0.0                 0.0      385  \n",
      "2                        0                0.0                 0.0     1704  \n",
      "3                        0                0.0                 0.0     1704  \n",
      "4                        0                0.0                 0.0      689  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Refund_Option</th>\n",
       "      <th>Refund_Option_Cancelled</th>\n",
       "      <th>Refund_Percentage</th>\n",
       "      <th>Automatic_Pay_Rate</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.00000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1612.248571</td>\n",
       "      <td>16.883095</td>\n",
       "      <td>3.34000</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>1612.565952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>650.943782</td>\n",
       "      <td>16.592762</td>\n",
       "      <td>3.70528</td>\n",
       "      <td>0.235312</td>\n",
       "      <td>0.156002</td>\n",
       "      <td>647.809644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1168.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1701.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2060.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>2047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4410.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>4200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  Refund_Option  Refund_Option_Cancelled  Refund_Percentage  \\\n",
       "count  4200.000000    4200.000000               4200.00000        4200.000000   \n",
       "mean   1612.248571      16.883095                  3.34000           0.572300   \n",
       "std     650.943782      16.592762                  3.70528           0.235312   \n",
       "min      75.000000       0.000000                  0.00000           0.000000   \n",
       "25%    1168.000000       6.000000                  1.00000           0.451613   \n",
       "50%    1701.000000      12.000000                  2.00000           0.600000   \n",
       "75%    2060.000000      23.000000                  5.00000           0.730769   \n",
       "max    4410.000000     257.000000                 45.00000           1.200000   \n",
       "\n",
       "       Automatic_Pay_Rate      Revenue  \n",
       "count         4200.000000  4200.000000  \n",
       "mean             0.208145  1612.565952  \n",
       "std              0.156002   647.809644  \n",
       "min              0.000000    79.000000  \n",
       "25%              0.100000  1172.000000  \n",
       "50%              0.200000  1699.000000  \n",
       "75%              0.294000  2047.000000  \n",
       "max              1.750000  4200.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"C:\\\\Users\\\\datel080\\\\Downloads\\\\Project_Work\\\\finance_model.csv\")\n",
    "#import pandas as pd\n",
    "#data_df = pd.read_csv(\"C:\\Users\\datel080\\Downloads\\Project_Work\\finance_model.csv\",index_col=0)\n",
    "#data_dfcrm_model\n",
    "\n",
    "print(df3.head())\n",
    "\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID Program_Code  Min_Seniority  Max_Seniority Origin_State  \\\n",
      "0   HG-449-40686           HG            4.0            5.0           CA   \n",
      "1  HG-2589-40686           HG            4.0            5.0           CA   \n",
      "2   HC-145-40705           HC            6.0            7.0           IN   \n",
      "3  HC-3525-40705           HC            7.0            8.0           IN   \n",
      "4  HC-2222-40691           HC           12.0           13.0           NE   \n",
      "\n",
      "   Days Travel_Type Departure_Date Return_Date  Participant   ...     \\\n",
      "0     2           A       05/23/11    05/24/11           29   ...      \n",
      "1     2           A       05/23/11    05/24/11           29   ...      \n",
      "2     5           A       06/11/11    06/15/11           16   ...      \n",
      "3     5           A       06/11/11    06/15/11           16   ...      \n",
      "4     5           A       05/28/11    06/01/11           35   ...      \n",
      "\n",
      "   Departure_Month   Type_Low  Type_High                 Type  \\\n",
      "0              May  Undefined  Undefined  Undefined-Undefined   \n",
      "1              May  Undefined  Undefined  Undefined-Undefined   \n",
      "2             June        5-8        5-8              5-8-5-8   \n",
      "3             June        5-8        5-8              5-8-5-8   \n",
      "4              May          2          2                  2-2   \n",
      "\n",
      "   Code_Aggregation Same_Type_Flag Enrollment  Participant_Ratio  \\\n",
      "0                 H              1        NaN           0.935484   \n",
      "1                 H              1        NaN           0.935484   \n",
      "2                 H              1   0.037500           0.833333   \n",
      "3                 H              1   0.037500           0.833333   \n",
      "4                 H              1   0.119863           0.875000   \n",
      "\n",
      "  Participant_Difference Retained  \n",
      "0                      2        0  \n",
      "1                      2        0  \n",
      "2                      3        0  \n",
      "3                      3        0  \n",
      "4                      5        0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min_Seniority</th>\n",
       "      <th>Max_Seniority</th>\n",
       "      <th>Days</th>\n",
       "      <th>Participant</th>\n",
       "      <th>Total_Participants</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Discounted</th>\n",
       "      <th>Company_Sponsor</th>\n",
       "      <th>Same_Type_Flag</th>\n",
       "      <th>Enrollment</th>\n",
       "      <th>Participant_Ratio</th>\n",
       "      <th>Participant_Difference</th>\n",
       "      <th>Retained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3967.000000</td>\n",
       "      <td>3926.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.256113</td>\n",
       "      <td>7.897606</td>\n",
       "      <td>4.736905</td>\n",
       "      <td>31.394762</td>\n",
       "      <td>34.360952</td>\n",
       "      <td>4.849048</td>\n",
       "      <td>2.964524</td>\n",
       "      <td>0.105714</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.066301</td>\n",
       "      <td>0.900733</td>\n",
       "      <td>2.966190</td>\n",
       "      <td>0.606667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.624928</td>\n",
       "      <td>1.771454</td>\n",
       "      <td>1.481672</td>\n",
       "      <td>29.173849</td>\n",
       "      <td>31.652099</td>\n",
       "      <td>4.844284</td>\n",
       "      <td>3.015073</td>\n",
       "      <td>0.307508</td>\n",
       "      <td>0.412023</td>\n",
       "      <td>0.082620</td>\n",
       "      <td>0.049191</td>\n",
       "      <td>2.899573</td>\n",
       "      <td>0.488548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.883279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045862</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.052632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Min_Seniority  Max_Seniority         Days  Participant  \\\n",
       "count    3967.000000    3926.000000  4200.000000  4200.000000   \n",
       "mean        7.256113       7.897606     4.736905    31.394762   \n",
       "std         1.624928       1.771454     1.481672    29.173849   \n",
       "min         2.000000       3.000000     1.000000     2.000000   \n",
       "25%         6.000000       7.000000     4.000000    13.000000   \n",
       "50%         7.000000       8.000000     5.000000    24.000000   \n",
       "75%         8.000000       9.000000     5.000000    40.000000   \n",
       "max        13.000000      13.000000    12.000000   300.000000   \n",
       "\n",
       "       Total_Participants    Cancelled   Discounted  Company_Sponsor  \\\n",
       "count         4200.000000  4200.000000  4200.000000      4200.000000   \n",
       "mean            34.360952     4.849048     2.964524         0.105714   \n",
       "std             31.652099     4.844284     3.015073         0.307508   \n",
       "min              2.000000     0.000000     0.000000         0.000000   \n",
       "25%             14.000000     2.000000     1.000000         0.000000   \n",
       "50%             26.000000     4.000000     2.000000         0.000000   \n",
       "75%             44.000000     7.000000     4.000000         0.000000   \n",
       "max            327.000000    46.000000    46.000000         1.000000   \n",
       "\n",
       "       Same_Type_Flag   Enrollment  Participant_Ratio  Participant_Difference  \\\n",
       "count     4200.000000  4032.000000        4200.000000             4200.000000   \n",
       "mean         0.783333     0.066301           0.900733                2.966190   \n",
       "std          0.412023     0.082620           0.049191                2.899573   \n",
       "min          0.000000     0.000922           0.600000                0.000000   \n",
       "25%          1.000000     0.021053           0.883279                1.000000   \n",
       "50%          1.000000     0.045862           0.909091                2.000000   \n",
       "75%          1.000000     0.087500           0.933333                4.000000   \n",
       "max          1.000000     2.052632           1.000000               47.000000   \n",
       "\n",
       "          Retained  \n",
       "count  4200.000000  \n",
       "mean      0.606667  \n",
       "std       0.488548  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"C:\\\\Users\\\\datel080\\\\Downloads\\\\Project_Work\\\\sales_model.csv\")\n",
    "#import pandas as pd\n",
    "#data_df = pd.read_csv(\"C:\\Users\\datel080\\Downloads\\Project_Work\\finance_model.csv\",index_col=0)\n",
    "#data_dfcrm_model\n",
    "\n",
    "print(df4.head())\n",
    "\n",
    "df4.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ID                                               text\n",
      "0   HD-668-40614   is the contest over for Destination Dragons? ...\n",
      "1  HD-1361-40692   thx for nothing on getting us out of the coun...\n",
      "2  HD-2211-40639   Hey friends! Stupid question - Can I split pa...\n",
      "3     SC-5-40706   if someone had bothered to inform us that the...\n",
      "4  CD-3439-40654           thanks so much for help Us, u r amazing! 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12837</td>\n",
       "      <td>12837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4200</td>\n",
       "      <td>12597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>HD-3509-40704</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID     text\n",
       "count           12837    12837\n",
       "unique           4200    12597\n",
       "top     HD-3509-40704   thanks\n",
       "freq                5       16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"C:\\\\Users\\\\datel080\\\\Downloads\\\\Project_Work\\\\twitter_model.csv\")\n",
    "#import pandas as pd\n",
    "#data_df = pd.read_csv(\"C:\\Users\\datel080\\Downloads\\Project_Work\\finance_model.csv\",index_col=0)\n",
    "#data_dfcrm_model\n",
    "\n",
    "print(df5.head()0)\n",
    "\n",
    "df5.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df2.boxplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset scaling and visualizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = StandardScaler(copy=False) #or alternatively use MinMaxScaler\n",
    "scaler2.fit(df2.astype(float)) # \n",
    "scaler2.transform(df2.astype(float))\n",
    "df2.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_scaled=pd.DataFrame(scaler2.transform(df2.astype(float))) \n",
    "df2_scaled.columns=df2.columns\n",
    "df2_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_scaled.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.apply(lambda s: df2.corrwith(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA fit\n",
    "from sklearn.decomposition import PCA\n",
    "# we can choose the number of components e.g. 10, the percentage of the total variance or set it to None (that means it automatically chooses the number of components)\n",
    "pca2 = PCA()\n",
    "pca2.fit(df2_scaled) #The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pca to transform the dataset\n",
    "df2_pca = pd.DataFrame(pca2.transform(df2_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's analyse what happened\n",
    "#VISUALIZE The amount of variance explained by each of the 10 selected principal components.\n",
    "pd.DataFrame(pca2.explained_variance_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The percentage of variance explained by each of the selected components.\n",
    "explained_var=pd.DataFrame(pca2.explained_variance_ratio_).transpose()\n",
    "explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The cumulative percentage of explained variance\n",
    "cum_explained_var=np.cumsum(pca2.explained_variance_ratio_)\n",
    "pd.DataFrame(cum_explained_var).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "ax = sns.barplot( data=explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca2.components_,index=['PC1','PC2','PC3','PC4','PC5','PC6'],columns=df2.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st component:\n",
    "\n",
    "The variables\n",
    "\n",
    "   - Condition\n",
    "   - Promptness\n",
    "   - Opening-times\n",
    "\n",
    "show a high correlation with the first component. This component can be summarized as an index of the **structure’s performances**\n",
    "\n",
    "### 2nd component:\n",
    "\n",
    "The variables\n",
    "   - Courtesy\n",
    "   - Clarity\n",
    "   - Competence\n",
    "\n",
    "show a high correlation with the second component. \n",
    "This component can be summarized as an index of the **personnel’s performance**\n",
    "\n",
    "**Notice that the Principal Components have negative values in the variables that they explain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_pca.columns=['PC1','PC2','PC3','PC4','PC5','PC6']\n",
    "df2_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=sns.scatterplot(x=\"PC1\", y=\"PC2\",\n",
    "              alpha=.3, \n",
    "              hue=\"PC6\", legend=False,\n",
    "              data=df2_pca);\n",
    "\n",
    "# add annotations one by one with a loop\n",
    "for line in range(0,df2_pca.shape[0]):\n",
    "     p1.text(df2_pca.PC1[line], df2_pca.PC2[line], line, horizontalalignment='left', size='medium', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that \n",
    " - centers 18,11 has a GOOD infrastructure but a BAD service\n",
    " - the group near 1,4,6 has BAD infrastructure but GOOD service quality \n",
    " - the group 0,3,2,9 has GOOD infrastructure and service\n",
    " - center 17 has BAD infrastructure and service!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer wisconsin (diagnostic) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload a toy datasets from scikit-learn\n",
    "#sklearn comes with a few small standard datasets that do not require to download any file from some external website\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer() #The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "\n",
    "#create the dataframe\n",
    "dataset_df = pd.DataFrame(dataset.data)\n",
    "columns = dataset.feature_names\n",
    "dataset_df.columns = columns\n",
    "\n",
    "print(dataset[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset visualization tools\n",
    "%matplotlib inline\n",
    "dataset_df.boxplot()\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset scaling and visualizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=False) #or alternatively use MinMaxScaler\n",
    "scaler.fit(dataset_df) \n",
    "scaler.transform(dataset_df) \n",
    "dataset_df.boxplot()\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = dataset_df.iloc[:,0]\n",
    "y = dataset_df.iloc[:,1]\n",
    "\n",
    "dataset_df['target'] = dataset.target  \n",
    "\n",
    "plt.scatter(x, y,alpha=0.2,c=dataset_df['target'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=\"mean perimeter\", y=\"mean area\",\n",
    "              hue=\"target\", alpha=.2,\n",
    "              data=dataset_df);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA fit\n",
    "from sklearn.decomposition import PCA\n",
    "# we can choose the number of components e.g. 10, the percentage of the total variance or set it to None (that means it automatically chooses the number of components)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(dataset_df) #The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pca to transform the dataset\n",
    "x_pca = pca.transform(dataset_df)\n",
    "print(\"Dataset shape before PCA: \", dataset_df.shape)\n",
    "print(\"Dataset shape after PCA: \", x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's analyse what happened\n",
    "#VISUALIZE The amount of variance explained by each of the 10 selected principal components.\n",
    "pd.DataFrame(pca.explained_variance_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The percentage of variance explained by each of the selected components.\n",
    "explained_var=pd.DataFrame(pca.explained_variance_ratio_).transpose()\n",
    "explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.barplot( data=explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The cumulative percentage of explained variance\n",
    "cum_explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "pd.DataFrame(cum_explained_var).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT the total percentage of explained variance \n",
    "print(cum_explained_var[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSING THE NUMBER OF COMPONENTS - we can plot the cumulative percentage of explained variance\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(cum_explained_var)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This previous curve quantifies how much of the total, 30-dimensional variance is contained within the first 10 components. \n",
    "For example, we see that the first 4 components contain approximately 79% of the variance, \n",
    "while you need around 6 components to describe close to 95% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.components_,index=['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9','pc10'],columns=dataset_df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let see the coordinates of the data in the PCA \n",
    "principalDf = pd.DataFrame(data = x_pca\n",
    "             , columns = ['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9','pc10'])\n",
    "principalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf['target']=dataset.target\n",
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data in the first PCA \n",
    "sns.scatterplot(x=\"pc1\",y=[0]*(principalDf['target'].size),\n",
    "              hue=\"target\", alpha=.2,\n",
    "              data =principalDf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data in the first two PCA \n",
    "sns.scatterplot(x=\"pc1\", y=\"pc2\",\n",
    "              hue=\"target\", alpha=.3,\n",
    "              data=principalDf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data in the first three PCA \n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(principalDf['pc1'], principalDf['pc2'],principalDf['pc3'], c=principalDf['target'], s=40)\n",
    "ax.view_init(30, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A PART FROM EXPLICITLY CHOOSE THE NUMBER OF PRINCIPAL COMPONENTS, YOU CAN RESORT TO SOME AUTOMATIC TOOLS SUCH AS:\n",
    "\n",
    "#(1) You can leave the pca implementation of sklearn to choose the number of components by using:\n",
    "    #Set n_components == 'mle' and svd_solver == 'full' and Minka’s MLE is used to guess the dimension. \n",
    "    \n",
    "pca = PCA(n_components='mle',svd_solver='full') \n",
    "pca.fit(dataset_df)\n",
    "pca.n_components_ \n",
    "#and then transform the dataset as we have already seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pca to transform the dataset\n",
    "x_pca = pca.transform(dataset_df)\n",
    "print(\"Dataset shape before PCA: \", dataset_df.shape)\n",
    "print(\"Dataset shape after PCA: \", x_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR (2) you can ask for the components able to explain a certain percentage of variance by using:\n",
    "    #Set 0 < n_components < 1 and svd_solver == 'full' to select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.\n",
    "\n",
    "pca = PCA(n_components=0.9,svd_solver='full') \n",
    "pca.fit(dataset_df)\n",
    "pca.n_components_ \n",
    "#and then transform the dataset as we have already seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pca to transform the dataset\n",
    "x_pca = pca.transform(dataset_df)\n",
    "print(\"Dataset shape before PCA: \", dataset_df.shape)\n",
    "print(\"Dataset shape after PCA: \", x_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV mtcars\n",
    "cars = pd.read_csv('mtcars.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The car types are a mix that includes sedans (Datsun, Ford, Honda,…), luxury sedans (Mercedes, Cadellac,..), muscle cars (Javelin, Challenger, Camaro…) and high-end sports cars (Porsche, Lotus, Maserati, Ferrari…)\n",
    "\n",
    "- \tmpg \tMiles/US Gallon \tmpg is the determinant of fuel efficiency\n",
    "- \tcyl \tNumber of cylinders \tData includes vehicles with 4,6,8 cylinder engines.\n",
    "- \tdisp \tDisplacement (cu.in.) \tDisplacement measures overall volume in the engine as a factor of cylinder circumfrance, depth and total number of cylinders. This metric gives a good proxy for the total amount of power the engine can generate.\n",
    "- \thp \tGross horsepower \tGross horsepower measures the theoretical output of an engine’s power output\n",
    "- \tdrat \tRear axle ratio \tThe rear axle gear ratio indicates the number of turns of the drive shaft for every one rotation of the wheel axle. \n",
    "- \tqsec \t1/4 mile time \tA performance measure, primarily of acceleration. Fastest time to travel 1/4 mile from standstill (in seconds).\n",
    "- \tvs \tV/S \tBinary variable signaling the engine cylinder configuration a V-shape (vs=0) or Straight Line (vs=1). V==0 and S==1. \n",
    "- \tam \tTransmission Type \tA binary variable signaling whether vehicle has automatic (am=0) or manual (am=1) transmission configuration.\n",
    "- \tgear \tNumber of forward gears \tNumber of gears in the transmission.\n",
    "- \tcarb \tNumber of carburetors \tThe number of carburetor barrels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset scaling and visualizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler3 = StandardScaler(copy=False) #or alternatively use MinMaxScaler\n",
    "scaler3.fit(cars.astype(float)) \n",
    "df_cars=pd.DataFrame(scaler3.transform(cars.astype(float))) \n",
    "df_cars.columns=cars.columns\n",
    "df_cars.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca3 = PCA()\n",
    "pca3.fit(df_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = pd.DataFrame(pca3.explained_variance_ratio_).transpose()\n",
    "sns.barplot(data=explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca3.components_,columns=cars.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_pca = pd.DataFrame(pca3.transform(df_cars),columns = ['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9','pc10','pc11']\n",
    "                        ,index=cars.index.values)\n",
    "cars_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2=sns.scatterplot(x=\"pc1\", y=\"pc2\",\n",
    "              alpha=.3,\n",
    "              data=cars_pca);\n",
    "# add annotations one by one with a loop\n",
    "for line in range(0,cars_pca.shape[0]):\n",
    "     p2.text(cars_pca.pc1[line], cars_pca.pc2[line], cars_pca.index[line], horizontalalignment='left', size='medium', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe\n",
    "iris_df = pd.DataFrame(iris.data)\n",
    "iris_df.columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "iris_scaler = StandardScaler(copy=False) #or alternatively use MinMaxScaler\n",
    "iris_scaler.fit(iris_df) # \n",
    "iris_scaler.transform(iris_df)\n",
    "iris_df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA fit\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The percentage of variance explained by each of the selected components.\n",
    "pd.DataFrame(pca.explained_variance_ratio_).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = pd.DataFrame(pca.explained_variance_ratio_).transpose()\n",
    "sns.barplot(data=explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.components_,columns=iris_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let see the coordinates of the data in the PCA \n",
    "iris_pca = pd.DataFrame(pca.transform(iris_df),columns = ['pc1', 'pc2','pc3','pc4']\n",
    "                        ,index=iris_df.index.values)\n",
    "iris_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data in the first two PCA \n",
    "sns.scatterplot(x=\"pc1\", y=\"pc2\",\n",
    "              hue=iris['target'], alpha=.3,\n",
    "              data=iris_pca);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
